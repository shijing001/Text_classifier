{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load modules\n",
    "import sys\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import pickle\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/DHE/ss1043/projects/HDS-MyChart/emergency'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os; os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('master_label_data_classifiers_25feb_20 - J_Wosik.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0_x', 'DEPARTMENT_NAME', 'ENCOUNTER_DATE', 'ENCOUNTER_ID',\n",
       "       'ENCOUNTER_TYPE', 'END_DATE', 'FINANCIAL_CLASS', 'INDICATOR',\n",
       "       'MESSAGE_DATE', 'MESSAGE_ID', 'MESSAGE_TEXT', 'MESSAGE_TO_FROM_PATIENT',\n",
       "       'MESSAGE_TO_FROM_PROVIDER', 'MESSAGE_TYPE', 'MRN', 'PAT_ID', 'PAT_NAME',\n",
       "       'PROVIDER_TYPE', 'START_DATE', 'Clean_Message', 'cluster_label',\n",
       "       'binary_cluster', 'doc_binary', 'doc_topic_perct', 'dominant_topic_ids',\n",
       "       'cluster_topic_interp', 'cluster', 'Urgency', '# of questions',\n",
       "       'statin related', 'Bleeding', 'Thanks/best wishes', 'ECG question',\n",
       "       'Stopping Meds Prior to Surgery', 'Requests for referrals',\n",
       "       'Simple Refill', 'Includes vitals', 'INR message'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    955\n",
       "-1.0    631\n",
       " 1.0    170\n",
       "Name: Urgency, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Urgency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    1106\n",
       " 0.0     206\n",
       " 1.0     114\n",
       "Name: Urgency, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Urgency.isin({0.0, 1.0,-1.0})].Urgency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = df[df.Urgency.isin({0.0, 1.0,-1.0})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1756, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data from json\n",
    "with open('original_labelled_data.json', 'r') as jf:\n",
    "    data=json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentences', 'labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences,labels=data['sentences'], data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "[it for it,lab in zip(sentences,labels) if lab==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=2020, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 764), (0, 504), (2, 136)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 955), (0, 631), (2, 170)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### traditional machine methods\n",
    "#### text preprocessing, feature engineering, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereâ€™s the complete script which performs the aforementioned data pre-processing steps, you can always add or remove steps which best suits the data set you are dealing with:\n",
    "\n",
    "    Remove Blank rows in Data, if any\n",
    "    Change all the text to lower case\n",
    "    Word Tokenization\n",
    "    Remove Stop words\n",
    "    Remove Non-alpha text\n",
    "    Word Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame.from_dict({'text':sentences, 'label':labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "full_data['text'].dropna(inplace=True)\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "full_data['text'] = [entry.lower() for entry in full_data['text']]\n",
    "# Step - c : Tokenization : In this each entry in the full_data will be broken into set of words\n",
    "full_data['text']= [word_tokenize(entry) for entry in full_data['text']]\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(full_data['text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    full_data.loc[index,'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test datasets split, use stratify for imbalanced data\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(full_data['text_final'],\n",
    "                        full_data['label'],test_size=0.2,random_state=2020, stratify=full_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 764), (0, 504), (2, 136)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Train_Y).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=1000)\n",
    "Tfidf_vect.fit(full_data['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 873)\t1.0\n",
      "  (1, 873)\t0.06572678903746632\n",
      "  (1, 861)\t0.1624260885519938\n",
      "  (1, 835)\t0.18206980132421033\n",
      "  (1, 801)\t0.2872862952725449\n",
      "  (1, 754)\t0.11124812693897355\n",
      "  (1, 725)\t0.11602391120370734\n",
      "  (1, 716)\t0.1624260885519938\n",
      "  (1, 699)\t0.18645716173186583\n",
      "  (1, 673)\t0.4117504337853171\n",
      "  (1, 609)\t0.13511053007674134\n",
      "  (1, 581)\t0.22978395987928016\n",
      "  (1, 556)\t0.11952149442384391\n",
      "  (1, 542)\t0.17632776397801436\n",
      "  (1, 528)\t0.15050837089038255\n",
      "  (1, 467)\t0.11331366088211951\n",
      "  (1, 459)\t0.22978395987928016\n",
      "  (1, 389)\t0.12966295679654294\n",
      "  (1, 370)\t0.11971499880895857\n",
      "  (1, 334)\t0.23809594790712943\n",
      "  (1, 271)\t0.20041430926101428\n",
      "  (1, 204)\t0.23809594790712943\n",
      "  (1, 193)\t0.1286629098780136\n",
      "  (1, 147)\t0.2229925711594858\n",
      "  (1, 107)\t0.12170742613351951\n",
      "  :\t:\n",
      "  (1399, 184)\t0.3019634706485925\n",
      "  (1399, 176)\t0.2130205124755125\n",
      "  (1399, 148)\t0.23644238296295578\n",
      "  (1399, 129)\t0.3543534206332035\n",
      "  (1399, 128)\t0.3543534206332035\n",
      "  (1399, 127)\t0.3224656033657172\n",
      "  (1399, 58)\t0.25160947379204723\n",
      "  (1400, 948)\t0.3476465397246388\n",
      "  (1400, 874)\t0.19011787875848435\n",
      "  (1400, 867)\t0.3736209705801268\n",
      "  (1400, 866)\t0.18991660383975228\n",
      "  (1400, 732)\t0.4653513603307976\n",
      "  (1400, 646)\t0.2452480377186581\n",
      "  (1400, 408)\t0.3338433779298358\n",
      "  (1400, 364)\t0.20959753138635576\n",
      "  (1400, 294)\t0.3198556157431164\n",
      "  (1400, 33)\t0.36461966469563367\n",
      "  (1401, 874)\t0.5239178932264134\n",
      "  (1401, 372)\t0.8517687721190516\n",
      "  (1402, 873)\t1.0\n",
      "  (1403, 725)\t0.3615331361307395\n",
      "  (1403, 678)\t0.45593213851214204\n",
      "  (1403, 648)\t0.5292040545743731\n",
      "  (1403, 525)\t0.48687981231987254\n",
      "  (1403, 270)\t0.3798826049302952\n"
     ]
    }
   ],
   "source": [
    "## vocabulary\n",
    "print(Tfidf_vect.vocabulary_)\n",
    "## features\n",
    "print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  85.79545454545455\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB(alpha=5.,fit_prior=False)\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.969     0.972       127\n",
      "           1      0.841     0.916     0.877       191\n",
      "           2      0.222     0.118     0.154        34\n",
      "\n",
      "    accuracy                          0.858       352\n",
      "   macro avg      0.680     0.667     0.668       352\n",
      "weighted avg      0.830     0.858     0.842       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_NB, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  89.48863636363636\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM -- linear kernel\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1., kernel='linear', degree=2, gamma='auto', random_state=82)#, class_weight='balanced')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.976     0.980       127\n",
      "           1      0.867     0.953     0.908       191\n",
      "           2      0.500     0.235     0.320        34\n",
      "\n",
      "    accuracy                          0.892       352\n",
      "   macro avg      0.784     0.722     0.736       352\n",
      "weighted avg      0.874     0.892     0.877       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_SVM, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM -- RBF kernel\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=10., kernel='rbf', gamma=1.)#, class_weight='balanced')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)# Use accuracy_score function to get the accuracy\n",
    "#print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Medium      1.000     0.961     0.980       127\n",
      "  Non-urgent      0.862     0.979     0.917       191\n",
      "      Urgent      0.615     0.235     0.340        34\n",
      "\n",
      "    accuracy                          0.901       352\n",
      "   macro avg      0.826     0.725     0.746       352\n",
      "weighted avg      0.888     0.901     0.884       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_SVM, target_names=['Medium','Non-urgent',\n",
    "                                                                   'Urgent'], digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mini-batch SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDClassifier(loss='hinge',max_iter=500, tol=1e-2, alpha=6.e-4,random_state=72)\n",
    "clf.fit(Train_X_Tfidf,Train_Y)\n",
    "predictions_SVM = clf.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1-score': 0.7477261102069286,\n",
       " 'precision': 0.7947840486540176,\n",
       " 'recall': 0.7313211387535598,\n",
       " 'support': 352}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['macro avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in [42,52,62,72,82]:\n",
    "    clf0 = SGDClassifier(loss='hinge',max_iter=500, tol=1e-2, alpha=1.e-3,\n",
    "                         random_state=seed)\n",
    "    calibrated_clf = CalibratedClassifierCV(clf0, cv=5, method='sigmoid')\n",
    "    calibrated_clf.fit(Train_X_Tfidf,Train_Y)\n",
    "    predictions_SVM = calibrated_clf.predict(Test_X_Tfidf) \n",
    "    ## temporary result\n",
    "    tmp = classification_report(Test_Y, predictions_SVM, digits=3,\n",
    "                            output_dict=True)\n",
    "    ## append to list\n",
    "    res['accuracy'].append(tmp['accuracy'])\n",
    "    res['f1-score'].append(tmp['macro avg']['f1-score'])\n",
    "    res['precision'].append(tmp['macro avg']['precision'])\n",
    "    res['recall'].append(tmp['macro avg']['recall'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8948863636363636, 0.0017967486705501962)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res['accuracy']),np.std(res['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7476424039899487, 0.007291395439872533)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res['f1-score']),np.std(res['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7945688418908233, 0.0067396360821895315)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res['precision']),np.std(res['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7313211387535598, 0.0062005444317027175)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res['recall']),np.std(res['recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioBERT  result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## precision, recall, f1, accuracy\n",
    "res=np.array([[0.780,0.772,0.776,0.892],\n",
    "              [0.791,0.765,0.775,0.895],\n",
    "              [0.778,0.756,0.764,.892],\n",
    "              [0.774,0.747,0.757,.892],\n",
    "              [0.747,0.751,0.749,.872]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.774 , 0.7582, 0.7642, 0.8886])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01462874, 0.00915205, 0.01038075, 0.00838093])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "## precision, recall, f1, accuracy -- label embedding BERT\n",
    "res=np.array([[0.790,0.788,0.789,0.892],\n",
    "              [0.779,0.801,0.788,0.878],\n",
    "              [0.766,0.776,0.770,.875],\n",
    "              [0.793,0.817,0.803,.889],\n",
    "              [0.790,0.804,0.796,.892]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7836, 0.7972, 0.7892, 0.8852])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01001199, 0.01404849, 0.01101635, 0.00724983])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_svm = calibrated_clf.predict_proba(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.976     0.980       127\n",
      "           1      0.867     0.953     0.908       191\n",
      "           2      0.500     0.235     0.320        34\n",
      "\n",
      "    accuracy                          0.892       352\n",
      "   macro avg      0.784     0.722     0.736       352\n",
      "weighted avg      0.874     0.892     0.877       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, predictions_SVM, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=classification_report(Test_Y, predictions_SVM, digits=3,\n",
    "                            output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8948863636363636"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'f1-score': 0.9802371541501976,\n",
       "  'precision': 0.9841269841269841,\n",
       "  'recall': 0.9763779527559056,\n",
       "  'support': 127},\n",
       " '1': {'f1-score': 0.91,\n",
       "  'precision': 0.8708133971291866,\n",
       "  'recall': 0.9528795811518325,\n",
       "  'support': 191},\n",
       " '2': {'f1-score': 0.35294117647058826,\n",
       "  'precision': 0.5294117647058824,\n",
       "  'recall': 0.2647058823529412,\n",
       "  'support': 34},\n",
       " 'accuracy': 0.8948863636363636,\n",
       " 'macro avg': {'f1-score': 0.7477261102069286,\n",
       "  'precision': 0.7947840486540176,\n",
       "  'recall': 0.7313211387535598,\n",
       "  'support': 352},\n",
       " 'weighted avg': {'f1-score': 0.8815344277757814,\n",
       "  'precision': 0.8787201302153456,\n",
       "  'recall': 0.8948863636363636,\n",
       "  'support': 352}}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function classification_report in module sklearn.metrics.classification:\n",
      "\n",
      "classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False)\n",
      "    Build a text report showing the main classification metrics\n",
      "    \n",
      "    Read more in the :ref:`User Guide <classification_report>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array, shape = [n_labels]\n",
      "        Optional list of label indices to include in the report.\n",
      "    \n",
      "    target_names : list of strings\n",
      "        Optional display names matching the labels (same order).\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    digits : int\n",
      "        Number of digits for formatting output floating point values.\n",
      "        When ``output_dict`` is ``True``, this will be ignored and the\n",
      "        returned values will not be rounded.\n",
      "    \n",
      "    output_dict : bool (default = False)\n",
      "        If True, return output as dict\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    report : string / dict\n",
      "        Text summary of the precision, recall, F1 score for each class.\n",
      "        Dictionary returned if output_dict is True. Dictionary has the\n",
      "        following structure::\n",
      "    \n",
      "            {'label 1': {'precision':0.5,\n",
      "                         'recall':1.0,\n",
      "                         'f1-score':0.67,\n",
      "                         'support':1},\n",
      "             'label 2': { ... },\n",
      "              ...\n",
      "            }\n",
      "    \n",
      "        The reported averages include macro average (averaging the unweighted\n",
      "        mean per label), weighted average (averaging the support-weighted mean\n",
      "        per label), sample average (only for multilabel classification) and\n",
      "        micro average (averaging the total true positives, false negatives and\n",
      "        false positives) it is only shown for multi-label or multi-class\n",
      "        with a subset of classes because it is accuracy otherwise.\n",
      "        See also:func:`precision_recall_fscore_support` for more details\n",
      "        on averages.\n",
      "    \n",
      "        Note that in binary classification, recall of the positive class\n",
      "        is also known as \"sensitivity\"; recall of the negative class is\n",
      "        \"specificity\".\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    precision_recall_fscore_support, confusion_matrix,\n",
      "    multilabel_confusion_matrix\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import classification_report\n",
      "    >>> y_true = [0, 1, 2, 2, 2]\n",
      "    >>> y_pred = [0, 0, 2, 2, 1]\n",
      "    >>> target_names = ['class 0', 'class 1', 'class 2']\n",
      "    >>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "         class 0       0.50      1.00      0.67         1\n",
      "         class 1       0.00      0.00      0.00         1\n",
      "         class 2       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "        accuracy                           0.60         5\n",
      "       macro avg       0.50      0.56      0.49         5\n",
      "    weighted avg       0.70      0.60      0.61         5\n",
      "    <BLANKLINE>\n",
      "    >>> y_pred = [1, 1, 0]\n",
      "    >>> y_true = [1, 1, 1]\n",
      "    >>> print(classification_report(y_true, y_pred, labels=[1, 2, 3]))\n",
      "                  precision    recall  f1-score   support\n",
      "    <BLANKLINE>\n",
      "               1       1.00      0.67      0.80         3\n",
      "               2       0.00      0.00      0.00         0\n",
      "               3       0.00      0.00      0.00         0\n",
      "    <BLANKLINE>\n",
      "       micro avg       1.00      0.67      0.80         3\n",
      "       macro avg       0.33      0.22      0.27         3\n",
      "    weighted avg       1.00      0.67      0.80         3\n",
      "    <BLANKLINE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess=keras.preprocessing.text.Tokenizer(num_words=5000, \n",
    "                                              lower=True, split=' ', char_level=False, \n",
    "                                               oov_token=True, document_count=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_ids=preprocess.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test datasets split, use stratify for imbalanced data\n",
    "train_x, test_x, train_y, test_y = train_test_split(txt_ids,\n",
    "                        labels,test_size=0.2,random_state=2020, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_x,test_x,\\\n",
    "to_categorical(train_y),to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404 train sequences\n",
      "352 test sequences\n",
      "Average train sequence length: 61\n",
      "Average test sequence length: 62\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Average train sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_train)), dtype=int)))\n",
    "print('Average test sequence length: {}'.format(\n",
    "    np.mean(list(map(len, x_test)), dtype=int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "# ngram_range = 2 will add bi-grams features\n",
    "ngram_range = 2\n",
    "max_features = 2000\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2-gram features\n",
      "Average train sequence length: 121\n",
      "Average test sequence length: 100\n"
     ]
    }
   ],
   "source": [
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in x_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    x_train = add_ngram(x_train, token_indice, ngram_range)\n",
    "    x_test = add_ngram(x_test, token_indice, ngram_range)\n",
    "    print('Average train sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_train)), dtype=int)))\n",
    "    print('Average test sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_test)), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (1404, 100)\n",
      "x_test shape: (352, 100)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DHE/ss1043/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1404 samples, validate on 352 samples\n",
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 1s 870us/step - loss: 1.0638 - accuracy: 0.7201 - val_loss: 1.0226 - val_accuracy: 0.7301\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 1s 516us/step - loss: 0.9756 - accuracy: 0.7628 - val_loss: 0.9215 - val_accuracy: 0.7358\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 1s 570us/step - loss: 0.8633 - accuracy: 0.7707 - val_loss: 0.8115 - val_accuracy: 0.7358\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 1s 528us/step - loss: 0.7537 - accuracy: 0.7742 - val_loss: 0.7221 - val_accuracy: 0.7443\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 1s 635us/step - loss: 0.6641 - accuracy: 0.7870 - val_loss: 0.6525 - val_accuracy: 0.7528\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 1s 511us/step - loss: 0.5890 - accuracy: 0.8091 - val_loss: 0.5932 - val_accuracy: 0.7784\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 1s 508us/step - loss: 0.5225 - accuracy: 0.8205 - val_loss: 0.5429 - val_accuracy: 0.7869\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 1s 570us/step - loss: 0.4638 - accuracy: 0.8319 - val_loss: 0.5048 - val_accuracy: 0.8011\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 1s 606us/step - loss: 0.4152 - accuracy: 0.8426 - val_loss: 0.4793 - val_accuracy: 0.8040\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 1s 521us/step - loss: 0.3758 - accuracy: 0.8462 - val_loss: 0.4590 - val_accuracy: 0.8153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1b086cee10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-urgent       0.80      0.99      0.89       127\n",
      "      Medium       0.83      0.84      0.83       191\n",
      "      Urgent       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.82       352\n",
      "   macro avg       0.54      0.61      0.57       352\n",
      "weighted avg       0.74      0.82      0.77       352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DHE/ss1043/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_predict0=model.predict(x_test)\n",
    "y_predict=np.argmax(y_predict0,axis=1)\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_predict, target_names=['Non-urgent',\n",
    "                                                                   'Medium','Urgent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Dense,Input,Embedding,Flatten, AveragePooling2D, Conv2D,Reshape\n",
    "from keras.models import Sequential,Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras.layers.merge import Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test datasets split, use stratify for imbalanced data\n",
    "train_x, test_x, train_y, test_y = train_test_split(sentences,\n",
    "                        labels,test_size=0.2,random_state=2020, stratify=labels)\n",
    "# Encoder = LabelEncoder()\n",
    "# train_y = Encoder.fit_transform(train_y)\n",
    "# test_y = Encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_file='../glove.6B/glove.6B.100d.txt'\n",
    "f = open(w2v_file, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_file='../glove.6B/glove.6B.100d.txt'\n",
    "def loadData_Tokenizer(X_train, X_test, MAX_NB_WORDS=75000,\n",
    "                       MAX_SEQUENCE_LENGTH=500, w2v_file=w2v_file):\n",
    "    \"\"\"\n",
    "    use glove embedding\n",
    "    \"\"\"\n",
    "    np.random.seed(7)\n",
    "    text = np.concatenate((X_train, X_test), axis=0)\n",
    "    text = np.array(text)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    indices = np.arange(text.shape[0])\n",
    "    # np.random.shuffle(indices)\n",
    "    text = text[indices]\n",
    "    print(text.shape)\n",
    "    X_train = text[0:len(X_train), ]\n",
    "    X_test = text[len(X_train):, ]\n",
    "    embeddings_index = {}\n",
    "    f = open(w2v_file, encoding=\"utf8\") ## GloVe file which could be download https://nlp.stanford.edu/projects/glove/\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            pass\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    return (X_train, X_test, word_index,embeddings_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model_CNN_Text(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=100, \n",
    "                         dropout=0.5):\n",
    "\n",
    "    \"\"\"\n",
    "        def buildModel_CNN(word_index, embeddings_index, nclasses, MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
    "        word_index in word index ,\n",
    "        embeddings_index is embeddings index, look at data_helper.py\n",
    "        nClasses is number of classes,\n",
    "        MAX_SEQUENCE_LENGTH is maximum lenght of text sequences,\n",
    "        EMBEDDING_DIM is an int value for dimention of word embedding look at data_helper.py\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            if len(embedding_matrix[i]) !=len(embedding_vector):\n",
    "                print(\"could not broadcast input array from shape\",str(len(embedding_matrix[i])),\n",
    "                                 \"into shape\",str(len(embedding_vector)),\" Please make sure your\"\n",
    "                                 \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
    "                exit(1)\n",
    "\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)\n",
    "\n",
    "    # applying a more complex convolutional approach\n",
    "    convs = []\n",
    "    filter_sizes = []\n",
    "    layer = 5\n",
    "    print(\"Filter  \",layer)\n",
    "    for fl in range(0,layer):\n",
    "        filter_sizes.append((fl+2,fl+2))\n",
    "\n",
    "    node = 128\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    emb = Reshape((500,10, 10), input_shape=(500,100))(embedded_sequences)\n",
    "\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv2D(node, padding=\"same\", kernel_size=fsz, activation='relu')(emb)\n",
    "        l_pool = AveragePooling2D(pool_size=(5,1), padding=\"same\")(l_conv)\n",
    "        #l_pool = Dropout(0.25)(l_pool)\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "    l_cov1 = Conv2D(node, (5,5), padding=\"same\", activation='relu')(l_merge)\n",
    "    l_cov1 = AveragePooling2D(pool_size=(5,2), padding=\"same\")(l_cov1)\n",
    "    l_cov2 = Conv2D(node, (5,5), padding=\"same\", activation='relu')(l_cov1)\n",
    "    l_pool2 = AveragePooling2D(pool_size=(5,2), padding=\"same\")(l_cov2)\n",
    "    l_cov2 = Dropout(dropout)(l_pool2)\n",
    "    l_flat = Flatten()(l_cov2)\n",
    "    l_dense = Dense(128, activation='relu')(l_flat)\n",
    "    l_dense = Dropout(dropout)(l_dense)\n",
    "\n",
    "    preds = Dense(nclasses, activation='softmax')(l_dense)\n",
    "    model = Model(sequence_input, preds)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method compile in module keras.engine.training:\n",
      "\n",
      "compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs) method of keras.engine.sequential.Sequential instance\n",
      "    Configures the model for training.\n",
      "    \n",
      "    # Arguments\n",
      "        optimizer: String (name of optimizer) or optimizer instance.\n",
      "            See [optimizers](/optimizers).\n",
      "        loss: String (name of objective function) or objective function or\n",
      "            `Loss` instance. See [losses](/losses).\n",
      "            If the model has multiple outputs, you can use a different loss\n",
      "            on each output by passing a dictionary or a list of losses.\n",
      "            The loss value that will be minimized by the model\n",
      "            will then be the sum of all individual losses.\n",
      "        metrics: List of metrics to be evaluated by the model\n",
      "            during training and testing. Typically you will use\n",
      "            `metrics=['accuracy']`. To specify different metrics for different\n",
      "            outputs of a multi-output model, you could also pass a dictionary,\n",
      "            such as\n",
      "            `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      "            You can also pass a list (len = len(outputs)) of lists of metrics\n",
      "            such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      "            `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      "        loss_weights: Optional list or dictionary specifying scalar\n",
      "            coefficients (Python floats) to weight the loss contributions\n",
      "            of different model outputs.\n",
      "            The loss value that will be minimized by the model\n",
      "            will then be the *weighted sum* of all individual losses,\n",
      "            weighted by the `loss_weights` coefficients.\n",
      "            If a list, it is expected to have a 1:1 mapping\n",
      "            to the model's outputs. If a dict, it is expected to map\n",
      "            output names (strings) to scalar coefficients.\n",
      "        sample_weight_mode: If you need to do timestep-wise\n",
      "            sample weighting (2D weights), set this to `\"temporal\"`.\n",
      "            `None` defaults to sample-wise weights (1D).\n",
      "            If the model has multiple outputs, you can use a different\n",
      "            `sample_weight_mode` on each output by passing a\n",
      "            dictionary or a list of modes.\n",
      "        weighted_metrics: List of metrics to be evaluated and weighted\n",
      "            by sample_weight or class_weight during training and testing.\n",
      "        target_tensors: By default, Keras will create placeholders for the\n",
      "            model's target, which will be fed with the target data during\n",
      "            training. If instead you would like to use your own\n",
      "            target tensors (in turn, Keras will not expect external\n",
      "            Numpy data for these targets at training time), you\n",
      "            can specify them via the `target_tensors` argument. It can be\n",
      "            a single tensor (for a single-output model), a list of tensors,\n",
      "            or a dict mapping output names to target tensors.\n",
      "        **kwargs: When using the Theano/CNTK backends, these arguments\n",
      "            are passed into `K.function`.\n",
      "            When using the TensorFlow backend,\n",
      "            these arguments are passed into `tf.Session.run`.\n",
      "    \n",
      "    # Raises\n",
      "        ValueError: In case of invalid arguments for\n",
      "            `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "help(model.compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   18,    7],\n",
       "       [   0,    0,    0, ..., 1227, 1228, 2872],\n",
       "       [   0,    0,    0, ...,    7, 2873, 3946],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  201,   38,    7],\n",
       "       [   0,    0,    0, ...,    0,   18,    7],\n",
       "       [   0,    0,    0, ...,   20,  290, 1893]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7623 unique tokens.\n",
      "(1756, 500)\n",
      "Total 400000 word vectors.\n",
      "Filter   5\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 500, 100)     762400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 500, 10, 10)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 500, 10, 128) 5248        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 500, 10, 128) 11648       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 500, 10, 128) 20608       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 500, 10, 128) 32128       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 500, 10, 128) 46208       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 100, 10, 128) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 100, 10, 128) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 100, 10, 128) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 100, 10, 128) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 100, 10, 128) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 10, 128) 0           average_pooling2d_1[0][0]        \n",
      "                                                                 average_pooling2d_2[0][0]        \n",
      "                                                                 average_pooling2d_3[0][0]        \n",
      "                                                                 average_pooling2d_4[0][0]        \n",
      "                                                                 average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 500, 10, 128) 409728      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 100, 5, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 100, 5, 128)  409728      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 20, 3, 128)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 3, 128)   0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7680)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          983168      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           2580        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,683,444\n",
      "Trainable params: 2,683,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train_Glove,X_test_Glove, word_index,embeddings_index = loadData_Tokenizer(train_x,test_x)\n",
    "\n",
    "\n",
    "model_CNN = Build_Model_CNN_Text(word_index,embeddings_index, 20)\n",
    "\n",
    "\n",
    "model_CNN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1404 samples, validate on 352 samples\n",
      "Epoch 1/4\n",
      " - 283s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.3047 - val_accuracy: 0.8097\n",
      "Epoch 2/4\n",
      " - 275s - loss: 0.0818 - accuracy: 0.9815 - val_loss: 1.4996 - val_accuracy: 0.8494\n",
      "Epoch 3/4\n",
      " - 278s - loss: 0.0238 - accuracy: 0.9922 - val_loss: 2.8516 - val_accuracy: 0.8636\n",
      "Epoch 4/4\n",
      " - 295s - loss: 0.0043 - accuracy: 0.9986 - val_loss: 2.4735 - val_accuracy: 0.8409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f54bc3d1ef0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN.fit(X_train_Glove, train_y,\n",
    "                              validation_data=(X_test_Glove, test_y),\n",
    "                              epochs=4,\n",
    "                              batch_size=16,\n",
    "                              verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       127\n",
      "           1       0.88      0.84      0.86       191\n",
      "           2       0.33      0.35      0.34        34\n",
      "\n",
      "    accuracy                           0.84       352\n",
      "   macro avg       0.71      0.72      0.72       352\n",
      "weighted avg       0.84      0.84      0.84       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model_CNN.predict(X_test_Glove)\n",
    "\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(test_y, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1.0: 1106, 0.0: 206, 1.0: 114})"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "#from pandas import ExcelWriter\n",
    "#from pandas import ExcelFile\n",
    "from transformers import BertForSequenceClassification,BertModel, BertConfig\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 977335.36B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "## set the padding\n",
    "tokenizer.pad_token = '[PAD]'\n",
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bert encoder  -- set output_hidden_states to be TRUE\n",
    "encoder = BertModel.from_pretrained('bert-base-uncased',output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 2,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"output_past\": true,\n",
       "  \"pruned_heads\": {},\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pading and truncation // mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tokenizer, sentences, MAX_LEN = 256):\n",
    "    \"\"\"\n",
    "    :params[in]: tokenizer, the configured tokenizer\n",
    "    :params[in]: sentences, list of strings\n",
    "    \"\"\"\n",
    "    # 1. Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    \n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        encoded_sent = tokenizer.encode(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            # This function also supports truncation and conversion\n",
    "                            # to pytorch tensors, but we need to do padding, so we\n",
    "                            # can't use these features :( .\n",
    "                            #max_length = 128,          # Truncate all sentences.\n",
    "                            #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )        \n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_sent)\n",
    "    \n",
    "    # We'll borrow the `pad_sequences` utility function to do this.\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    # Set the maximum sequence length.\n",
    "    # maximum training sentence length of 87...\n",
    "    \n",
    "    print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "    \n",
    "    print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "    \n",
    "    # Pad our input tokens with value 0.\n",
    "    # \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "    # as opposed to the beginning.\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                              value=0, truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    print('\\nDone.')\n",
    "    # Create attention masks\n",
    "    attention_masks = []\n",
    "    # For each sentence...\n",
    "    for sent in input_ids:\n",
    "        \n",
    "        # Create the attention mask.\n",
    "        #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "        #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        \n",
    "        # Store the attention mask for this sentence.\n",
    "        attention_masks.append(att_mask)\n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### an example\n",
    "sentences = ['I am working at Duke university', 'Duke is at Durham, North carolina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 256 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "input_ids,attention_masks=preprocess_data(tokenizer, sentences, MAX_LEN = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 101, 1045, 2572, 2551, 2012, 3804, 2118,  102,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0],\n",
       "       [ 101, 3804, 2003, 2012, 9296, 1010, 2167, 3792,  102,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.LongTensor(input_ids)\n",
    "train_masks = torch.LongTensor(attention_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=encoder(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on BertModel in module transformers.modeling_bert object:\n",
      "\n",
      "class BertModel(BertPreTrainedModel)\n",
      " |  BertModel(config)\n",
      " |  \n",
      " |  The bare Bert Model transformer outputting raw hidden-states without any specific head on top.    The BERT model was proposed in\n",
      " |  `BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding`_\n",
      " |  by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova. It's a bidirectional transformer\n",
      " |  pre-trained using a combination of masked language modeling objective and next sentence prediction\n",
      " |  on a large corpus comprising the Toronto Book Corpus and Wikipedia.\n",
      " |  \n",
      " |  This model is a PyTorch `torch.nn.Module`_ sub-class. Use it as a regular PyTorch Module and\n",
      " |  refer to the PyTorch documentation for all matter related to general usage and behavior.\n",
      " |  \n",
      " |  .. _`BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding`:\n",
      " |      https://arxiv.org/abs/1810.04805\n",
      " |  \n",
      " |  .. _`torch.nn.Module`:\n",
      " |      https://pytorch.org/docs/stable/nn.html#module\n",
      " |  \n",
      " |  Parameters:\n",
      " |      config (:class:`~transformers.BertConfig`): Model configuration class with all the parameters of the model. \n",
      " |          Initializing with a config file does not load the weights associated with the model, only the configuration.\n",
      " |          Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n",
      " |  \n",
      " |  Inputs:\n",
      " |      **input_ids**: ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``:\n",
      " |          Indices of input sequence tokens in the vocabulary.\n",
      " |          To match pre-training, BERT input sequence should be formatted with [CLS] and [SEP] tokens as follows:\n",
      " |  \n",
      " |          (a) For sequence pairs:\n",
      " |  \n",
      " |              ``tokens:         [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]``\n",
      " |              \n",
      " |              ``token_type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1``\n",
      " |  \n",
      " |          (b) For single sequences:\n",
      " |  \n",
      " |              ``tokens:         [CLS] the dog is hairy . [SEP]``\n",
      " |              \n",
      " |              ``token_type_ids:   0   0   0   0  0     0   0``\n",
      " |  \n",
      " |          Bert is a model with absolute position embeddings so it's usually advised to pad the inputs on\n",
      " |          the right rather than the left.\n",
      " |  \n",
      " |          Indices can be obtained using :class:`transformers.BertTokenizer`.\n",
      " |          See :func:`transformers.PreTrainedTokenizer.encode` and\n",
      " |          :func:`transformers.PreTrainedTokenizer.convert_tokens_to_ids` for details.\n",
      " |      **attention_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, sequence_length)``:\n",
      " |          Mask to avoid performing attention on padding token indices.\n",
      " |          Mask values selected in ``[0, 1]``:\n",
      " |          ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
      " |      **token_type_ids**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``:\n",
      " |          Segment token indices to indicate first and second portions of the inputs.\n",
      " |          Indices are selected in ``[0, 1]``: ``0`` corresponds to a `sentence A` token, ``1``\n",
      " |          corresponds to a `sentence B` token\n",
      " |          (see `BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding`_ for more details).\n",
      " |      **position_ids**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``:\n",
      " |          Indices of positions of each input sequence tokens in the position embeddings.\n",
      " |          Selected in the range ``[0, config.max_position_embeddings - 1]``.\n",
      " |      **head_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(num_heads,)`` or ``(num_layers, num_heads)``:\n",
      " |          Mask to nullify selected heads of the self-attention modules.\n",
      " |          Mask values selected in ``[0, 1]``:\n",
      " |          ``1`` indicates the head is **not masked**, ``0`` indicates the head is **masked**.\n",
      " |  \n",
      " |  Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
      " |      **last_hidden_state**: ``torch.FloatTensor`` of shape ``(batch_size, sequence_length, hidden_size)``\n",
      " |          Sequence of hidden-states at the output of the last layer of the model.\n",
      " |      **pooler_output**: ``torch.FloatTensor`` of shape ``(batch_size, hidden_size)``\n",
      " |          Last layer hidden-state of the first token of the sequence (classification token)\n",
      " |          further processed by a Linear layer and a Tanh activation function. The Linear\n",
      " |          layer weights are trained from the next sentence prediction (classification)\n",
      " |          objective during Bert pretraining. This output is usually *not* a good summary\n",
      " |          of the semantic content of the input, you're often better with averaging or pooling\n",
      " |          the sequence of hidden-states for the whole input sequence.\n",
      " |      **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
      " |          list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
      " |          of shape ``(batch_size, sequence_length, hidden_size)``:\n",
      " |          Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
      " |      **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
      " |          list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
      " |          Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
      " |      model = BertModel.from_pretrained('bert-base-uncased')\n",
      " |      input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
      " |      outputs = model(input_ids)\n",
      " |      last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BertModel\n",
      " |      BertPreTrainedModel\n",
      " |      transformers.modeling_utils.PreTrainedModel\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, config)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BertPreTrainedModel:\n",
      " |  \n",
      " |  load_tf_weights = load_tf_weights_in_bert(model, config, tf_checkpoint_path)\n",
      " |      Load tf checkpoints in a pytorch model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BertPreTrainedModel:\n",
      " |  \n",
      " |  base_model_prefix = 'bert'\n",
      " |  \n",
      " |  config_class = <class 'transformers.configuration_bert.BertConfig'>\n",
      " |      :class:`~transformers.BertConfig` is the configuration class to store the configuration of a\n",
      " |      `BertModel`.\n",
      " |      \n",
      " |      \n",
      " |      Arguments:\n",
      " |          vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n",
      " |          hidden_size: Size of the encoder layers and the pooler layer.\n",
      " |          num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
      " |          num_attention_heads: Number of attention heads for each attention layer in\n",
      " |              the Transformer encoder.\n",
      " |          intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n",
      " |              layer in the Transformer encoder.\n",
      " |          hidden_act: The non-linear activation function (function or string) in the\n",
      " |              encoder and pooler. If string, \"gelu\", \"relu\", \"swish\" and \"gelu_new\" are supported.\n",
      " |          hidden_dropout_prob: The dropout probabilitiy for all fully connected\n",
      " |              layers in the embeddings, encoder, and pooler.\n",
      " |          attention_probs_dropout_prob: The dropout ratio for the attention\n",
      " |              probabilities.\n",
      " |          max_position_embeddings: The maximum sequence length that this model might\n",
      " |              ever be used with. Typically set this to something large just in case\n",
      " |              (e.g., 512 or 1024 or 2048).\n",
      " |          type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n",
      " |              `BertModel`.\n",
      " |          initializer_range: The sttdev of the truncated_normal_initializer for\n",
      " |              initializing all weight matrices.\n",
      " |          layer_norm_eps: The epsilon used by LayerNorm.\n",
      " |  \n",
      " |  pretrained_model_archive_map = {'bert-base-cased': 'https://s3.amazona...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from transformers.modeling_utils.PreTrainedModel:\n",
      " |  \n",
      " |  init_weights(self)\n",
      " |      Initialize and prunes weights if needed.\n",
      " |  \n",
      " |  prune_heads(self, heads_to_prune)\n",
      " |      Prunes heads of the base model.\n",
      " |      \n",
      " |      Arguments:\n",
      " |      \n",
      " |          heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n",
      " |          E.g. {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n",
      " |  \n",
      " |  resize_token_embeddings(self, new_num_tokens=None)\n",
      " |      Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n",
      " |      Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n",
      " |      \n",
      " |      Arguments:\n",
      " |      \n",
      " |          new_num_tokens: (`optional`) int:\n",
      " |              New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n",
      " |              If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n",
      " |      \n",
      " |      Return: ``torch.nn.Embeddings``\n",
      " |          Pointer to the input tokens Embeddings Module of the model\n",
      " |  \n",
      " |  save_pretrained(self, save_directory)\n",
      " |      Save a model and its configuration file to a directory, so that it\n",
      " |      can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from transformers.modeling_utils.PreTrainedModel:\n",
      " |  \n",
      " |  from_pretrained(pretrained_model_name_or_path, *model_args, **kwargs) from builtins.type\n",
      " |      Instantiate a pretrained pytorch model from a pre-trained model configuration.\n",
      " |      \n",
      " |      The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n",
      " |      To train the model, you should first set it back in training mode with ``model.train()``\n",
      " |      \n",
      " |      The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n",
      " |      It is up to you to train those weights with a downstream fine-tuning task.\n",
      " |      \n",
      " |      The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          pretrained_model_name_or_path: either:\n",
      " |      \n",
      " |              - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n",
      " |              - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n",
      " |              - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n",
      " |              - None if you are both providing the configuration and state dictionary (resp. with keyword arguments ``config`` and ``state_dict``)\n",
      " |      \n",
      " |          model_args: (`optional`) Sequence of positional arguments:\n",
      " |              All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n",
      " |      \n",
      " |          config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n",
      " |              Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n",
      " |      \n",
      " |              - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n",
      " |              - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n",
      " |              - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n",
      " |      \n",
      " |          state_dict: (`optional`) dict:\n",
      " |              an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n",
      " |              This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n",
      " |              In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n",
      " |      \n",
      " |          cache_dir: (`optional`) string:\n",
      " |              Path to a directory in which a downloaded pre-trained model\n",
      " |              configuration should be cached if the standard cache should not be used.\n",
      " |      \n",
      " |          force_download: (`optional`) boolean, default False:\n",
      " |              Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n",
      " |      \n",
      " |          proxies: (`optional`) dict, default None:\n",
      " |              A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n",
      " |              The proxies are used on each request.\n",
      " |      \n",
      " |          output_loading_info: (`optional`) boolean:\n",
      " |              Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n",
      " |      \n",
      " |          kwargs: (`optional`) Remaining dictionary of keyword arguments:\n",
      " |              Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n",
      " |      \n",
      " |              - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n",
      " |              - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n",
      " |          model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n",
      " |          model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n",
      " |          assert model.config.output_attention == True\n",
      " |          # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n",
      " |          config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n",
      " |          model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self, requires_grad=True)\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3638,  0.5134,  0.5495,  ..., -0.4841,  0.4963, -0.5592],\n",
       "         [ 0.2451, -0.1647,  0.3254,  ...,  0.0251,  0.6870,  0.3468],\n",
       "         [-0.1145,  0.4743,  0.3670,  ..., -0.1040,  0.4522,  0.1831],\n",
       "         ...,\n",
       "         [ 0.4062,  0.1322,  0.8410,  ..., -0.7967,  0.3255, -1.1899],\n",
       "         [ 0.2683,  0.0852,  0.9596,  ..., -0.7396,  0.2321, -1.0489],\n",
       "         [ 0.4787, -0.0018,  0.9689,  ..., -0.8042,  0.3525, -1.4292]],\n",
       "\n",
       "        [[-0.3720,  0.4194,  0.3879,  ..., -0.4801,  0.2841, -0.9154],\n",
       "         [-0.5130,  0.0353,  1.1188,  ..., -0.2336,  0.7592, -0.0448],\n",
       "         [-0.4853,  0.3472,  0.1404,  ..., -0.1242,  0.0666,  0.6161],\n",
       "         ...,\n",
       "         [ 0.5417,  0.1160,  0.8503,  ..., -0.8669,  0.0889, -1.2774],\n",
       "         [ 0.4392,  0.0624,  0.9680,  ..., -0.8067,  0.0308, -1.2666],\n",
       "         [ 0.6183, -0.0764,  0.9619,  ..., -0.8852,  0.1123, -1.6548]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4736, -0.3670, -0.9379,  ..., -0.6772, -0.4092,  0.3748],\n",
       "        [-0.2237, -0.4750, -0.9885,  ..., -0.8886, -0.3218,  0.0244]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [-3.3997e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
       "            8.9008e-01,  1.6575e-01],\n",
       "          [-6.3496e-01,  1.9748e-01,  2.5116e-01,  ..., -4.0819e-02,\n",
       "            1.3468e+00, -6.9357e-01],\n",
       "          ...,\n",
       "          [ 1.2490e-01, -4.9897e-01, -1.1414e-01,  ..., -3.4521e-01,\n",
       "           -5.5017e-01,  1.8253e-02],\n",
       "          [ 1.6472e-01, -6.4177e-01,  3.7283e-01,  ..., -5.6678e-01,\n",
       "           -1.9548e-01, -1.8885e-01],\n",
       "          [ 4.3010e-01, -8.7304e-01,  2.0456e-01,  ..., -2.8683e-01,\n",
       "           -7.8286e-01, -3.8871e-01]],\n",
       " \n",
       "         [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "            3.8253e-02,  1.6400e-01],\n",
       "          [ 2.6300e-01,  9.6157e-02, -7.1425e-01,  ..., -6.0576e-01,\n",
       "           -1.0222e+00, -3.7969e-02],\n",
       "          [-6.2703e-01, -6.3313e-02, -3.1428e-01,  ...,  3.4265e-01,\n",
       "            4.6361e-01,  4.5937e-01],\n",
       "          ...,\n",
       "          [ 1.2490e-01, -4.9897e-01, -1.1414e-01,  ..., -3.4521e-01,\n",
       "           -5.5017e-01,  1.8253e-02],\n",
       "          [ 1.6472e-01, -6.4177e-01,  3.7283e-01,  ..., -5.6678e-01,\n",
       "           -1.9548e-01, -1.8885e-01],\n",
       "          [ 4.3010e-01, -8.7304e-01,  2.0456e-01,  ..., -2.8683e-01,\n",
       "           -7.8286e-01, -3.8871e-01]]], grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[ 0.2436, -0.1949,  0.0217,  ...,  0.0571,  0.1867,  0.0688],\n",
       "          [ 0.2185, -0.2689, -0.1856,  ...,  0.7726,  0.9955,  0.0874],\n",
       "          [-0.4147, -0.5242, -0.3249,  ...,  0.0795,  1.5055, -0.8361],\n",
       "          ...,\n",
       "          [ 0.3689, -0.2967, -0.0732,  ..., -0.2823, -0.0263, -0.0675],\n",
       "          [ 0.3683, -0.5172,  0.3659,  ..., -0.3499,  0.0916, -0.3627],\n",
       "          [ 0.6803, -0.6628,  0.2063,  ..., -0.0731, -0.3624, -0.4626]],\n",
       " \n",
       "         [[ 0.1653, -0.2035, -0.0286,  ...,  0.1932,  0.0580, -0.0337],\n",
       "          [ 0.2433, -0.2930, -0.8980,  ..., -0.4330, -0.7699,  0.0920],\n",
       "          [-1.1096, -0.8025, -0.6726,  ...,  0.3864,  0.7196,  0.7601],\n",
       "          ...,\n",
       "          [ 0.3733, -0.2909, -0.0797,  ..., -0.2793, -0.0311, -0.0716],\n",
       "          [ 0.3736, -0.5113,  0.3620,  ..., -0.3502,  0.0884, -0.3654],\n",
       "          [ 0.6851, -0.6585,  0.2018,  ..., -0.0703, -0.3669, -0.4654]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[ 0.0368, -0.6593,  0.2463,  ...,  0.2473, -0.2111,  0.0853],\n",
       "          [-0.1254, -0.7352, -0.0695,  ...,  0.5576,  0.6142,  0.9637],\n",
       "          [-0.5946, -0.6105, -0.4384,  ..., -0.1784,  1.6339, -0.3781],\n",
       "          ...,\n",
       "          [ 0.6009, -0.7738,  0.4281,  ..., -0.4830,  0.0562, -0.3986],\n",
       "          [ 0.6475, -0.9678,  1.0245,  ..., -0.5269,  0.1079, -0.8316],\n",
       "          [ 0.9810, -1.1307,  0.8206,  ..., -0.3039, -0.4498, -1.0671]],\n",
       " \n",
       "         [[-0.0437, -0.6110,  0.1635,  ...,  0.3907, -0.4311,  0.0158],\n",
       "          [ 0.2740, -0.4656, -0.9445,  ..., -0.0622, -1.2899,  0.0916],\n",
       "          [-0.9957, -1.1045, -0.2011,  ...,  0.3839,  0.2206,  0.9784],\n",
       "          ...,\n",
       "          [ 0.7472, -0.8628,  0.4430,  ..., -0.4374,  0.1212, -0.3075],\n",
       "          [ 0.7783, -1.1060,  1.0203,  ..., -0.5127,  0.1634, -0.6774],\n",
       "          [ 1.1084, -1.2899,  0.8616,  ..., -0.2512, -0.3971, -0.9560]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[ 1.2891e-03, -3.1131e-01,  1.7839e-01,  ..., -1.5677e-02,\n",
       "           -1.9392e-01,  3.3101e-02],\n",
       "          [-1.2281e-01, -8.1563e-02,  1.4207e-01,  ...,  6.2241e-01,\n",
       "            1.5609e-01,  9.7247e-01],\n",
       "          [-9.8547e-01, -1.6766e-01, -4.5104e-01,  ...,  1.5999e-01,\n",
       "            1.1638e+00,  6.5870e-02],\n",
       "          ...,\n",
       "          [ 5.9506e-01, -9.1362e-01,  4.8461e-01,  ..., -2.0508e-01,\n",
       "            8.5065e-02, -4.5784e-01],\n",
       "          [ 6.6905e-01, -1.0193e+00,  1.1543e+00,  ..., -2.8267e-01,\n",
       "            2.0707e-01, -8.8393e-01],\n",
       "          [ 9.3073e-01, -1.2220e+00,  9.1478e-01,  ...,  1.7097e-02,\n",
       "           -2.3026e-01, -1.1395e+00]],\n",
       " \n",
       "         [[-7.1061e-02, -2.8477e-01,  1.0959e-02,  ...,  7.1562e-02,\n",
       "           -2.8385e-01,  4.3185e-02],\n",
       "          [ 1.0527e-01, -6.2811e-01, -4.4548e-01,  ..., -2.8441e-01,\n",
       "           -1.3766e+00, -8.0233e-02],\n",
       "          [-1.4725e+00, -5.8467e-01,  1.4188e-01,  ...,  2.9568e-01,\n",
       "           -3.3773e-01,  9.5436e-01],\n",
       "          ...,\n",
       "          [ 8.1578e-01, -9.5916e-01,  5.8821e-01,  ..., -1.6670e-01,\n",
       "            1.2932e-01, -3.3939e-01],\n",
       "          [ 8.4418e-01, -1.1251e+00,  1.1668e+00,  ..., -2.6608e-01,\n",
       "            2.1234e-01, -6.9474e-01],\n",
       "          [ 1.1042e+00, -1.3376e+00,  9.6012e-01,  ...,  2.1919e-02,\n",
       "           -1.7111e-01, -1.0020e+00]]], grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.0477, -0.8262, -0.2797,  ..., -0.1671, -0.0279,  0.3666],\n",
       "          [-0.4020, -0.0172,  0.0171,  ...,  0.3603,  0.3692,  1.0682],\n",
       "          [-1.1988, -0.3423, -0.2525,  ...,  0.5729,  0.7827,  0.0766],\n",
       "          ...,\n",
       "          [ 0.5048, -0.7540,  0.2515,  ..., -0.3059,  0.7689, -0.1356],\n",
       "          [ 0.6630, -0.8730,  0.8228,  ..., -0.3135,  0.8736, -0.6328],\n",
       "          [ 1.0367, -1.1163,  0.6003,  ..., -0.0969,  0.3883, -1.0655]],\n",
       " \n",
       "         [[-0.0313, -0.8875, -0.4549,  ..., -0.0915,  0.0376,  0.3481],\n",
       "          [-0.1306, -0.5249, -0.3997,  ..., -0.4354, -0.8299, -0.2869],\n",
       "          [-1.4379, -0.2809,  0.1018,  ..., -0.2146, -0.0036,  1.3138],\n",
       "          ...,\n",
       "          [ 0.8276, -0.8498,  0.3500,  ..., -0.2567,  0.6001, -0.0167],\n",
       "          [ 0.9053, -1.0166,  0.8185,  ..., -0.3192,  0.6671, -0.4821],\n",
       "          [ 1.2348, -1.2884,  0.5926,  ..., -0.0392,  0.2071, -0.8992]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.1562, -0.9611, -0.1847,  ...,  0.2358,  0.1751,  0.3858],\n",
       "          [-0.1932,  0.0128,  0.0243,  ...,  0.9922,  0.6990,  1.0416],\n",
       "          [-0.8509, -0.0282, -0.6603,  ...,  1.1611,  0.6459, -0.2842],\n",
       "          ...,\n",
       "          [ 0.6994, -0.4339,  0.1408,  ...,  0.0672,  0.8912, -0.0691],\n",
       "          [ 0.7283, -0.6036,  0.6756,  ...,  0.0945,  0.9202, -0.4129],\n",
       "          [ 1.0788, -0.8798,  0.5417,  ...,  0.2329,  0.6257, -0.9243]],\n",
       " \n",
       "         [[-0.1093, -0.9906, -0.3709,  ...,  0.3718,  0.2565,  0.3860],\n",
       "          [ 0.1133, -0.3674,  0.1983,  ..., -0.1787, -0.5574, -0.2941],\n",
       "          [-0.8944,  0.4158,  0.0986,  ...,  0.3451,  0.2630,  1.0015],\n",
       "          ...,\n",
       "          [ 1.0068, -0.5213,  0.2128,  ...,  0.2221,  0.6589,  0.0879],\n",
       "          [ 1.0201, -0.6689,  0.6278,  ...,  0.1643,  0.6959, -0.2331],\n",
       "          [ 1.3529, -1.0151,  0.5229,  ...,  0.2956,  0.4217, -0.7529]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.3039, -0.5966,  0.2245,  ...,  0.3058,  0.5301, -0.0805],\n",
       "          [-0.1294,  0.2625,  0.0249,  ...,  0.6817,  0.9149,  0.9066],\n",
       "          [-0.6932, -0.0823, -0.3825,  ...,  0.2703,  0.9565, -0.2252],\n",
       "          ...,\n",
       "          [ 0.4248, -0.1884,  0.4875,  ..., -0.2817,  0.8612, -0.3728],\n",
       "          [ 0.3090, -0.2949,  0.9826,  ..., -0.2485,  0.7894, -0.7083],\n",
       "          [ 0.6687, -0.5621,  0.8180,  ..., -0.2007,  0.6216, -1.2104]],\n",
       " \n",
       "         [[-0.2932, -0.7126, -0.0471,  ...,  0.4751,  0.5066, -0.1891],\n",
       "          [-0.1853, -0.2198,  0.1706,  ..., -0.3967, -0.2122, -0.1768],\n",
       "          [-0.5238,  0.7701, -0.2180,  ...,  0.0598,  0.6211,  0.8243],\n",
       "          ...,\n",
       "          [ 0.7174, -0.1877,  0.4962,  ..., -0.2220,  0.6968, -0.2751],\n",
       "          [ 0.6319, -0.3112,  0.8855,  ..., -0.2559,  0.6528, -0.6246],\n",
       "          [ 0.9676, -0.6823,  0.7488,  ..., -0.2198,  0.4618, -1.1382]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.3413, -0.7331,  0.8830,  ...,  0.2645,  0.3590, -0.2735],\n",
       "          [-0.0183,  0.3960,  0.2665,  ...,  0.7247,  0.9371,  0.6663],\n",
       "          [-0.7359,  0.0189, -0.0676,  ...,  0.1971,  0.7991, -0.1104],\n",
       "          ...,\n",
       "          [ 0.6777,  0.0614,  0.6181,  ..., -0.2261,  0.7365, -0.6187],\n",
       "          [ 0.4740, -0.0697,  1.0546,  ..., -0.0288,  0.6542, -0.8503],\n",
       "          [ 0.9432, -0.3455,  0.9058,  ..., -0.0874,  0.6234, -1.3450]],\n",
       " \n",
       "         [[-0.3425, -0.9082,  0.5536,  ...,  0.3978,  0.2255, -0.4234],\n",
       "          [-0.1462,  0.0149,  0.4985,  ..., -0.0127, -0.0567, -0.3757],\n",
       "          [-0.4738,  0.5671, -0.5873,  ...,  0.6906, -0.1443,  0.8962],\n",
       "          ...,\n",
       "          [ 0.9628,  0.1062,  0.6590,  ..., -0.3135,  0.6177, -0.5465],\n",
       "          [ 0.8258, -0.0450,  0.9959,  ..., -0.1985,  0.5522, -0.8127],\n",
       "          [ 1.2200, -0.4239,  0.8785,  ..., -0.2536,  0.4951, -1.2989]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.1600, -0.4116,  0.5731,  ..., -0.3499,  0.2776, -0.4762],\n",
       "          [ 0.1937,  0.5831,  0.1298,  ...,  0.3277,  0.8669,  0.6426],\n",
       "          [-0.3484,  0.3273,  0.0215,  ...,  0.1445,  0.9143, -0.0828],\n",
       "          ...,\n",
       "          [ 0.5631, -0.0835,  0.7730,  ..., -0.3854,  0.7980, -0.7731],\n",
       "          [ 0.3509, -0.2439,  1.1302,  ..., -0.1769,  0.6655, -0.9886],\n",
       "          [ 0.7677, -0.4954,  1.0054,  ..., -0.1791,  0.6916, -1.4945]],\n",
       " \n",
       "         [[-0.2070, -0.5420,  0.2084,  ..., -0.3989,  0.1973, -0.5304],\n",
       "          [-0.1799, -0.0663,  0.4990,  ..., -0.2369, -0.2498, -0.5189],\n",
       "          [-0.1079,  0.5034, -0.0522,  ...,  0.4569,  0.1052,  0.3482],\n",
       "          ...,\n",
       "          [ 0.8511, -0.1558,  0.7835,  ..., -0.4487,  0.7720, -0.6599],\n",
       "          [ 0.7307, -0.3182,  1.1362,  ..., -0.2998,  0.6501, -0.9239],\n",
       "          [ 1.0409, -0.6742,  0.9947,  ..., -0.2993,  0.6474, -1.4028]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-1.1983e-01, -3.0055e-02,  5.6950e-01,  ..., -2.9875e-01,\n",
       "            1.3934e-01, -6.2728e-01],\n",
       "          [ 4.7796e-01,  4.5010e-01,  8.4183e-02,  ..., -7.6904e-02,\n",
       "            5.6628e-01,  4.6304e-01],\n",
       "          [-2.6975e-02,  4.7971e-01, -1.1582e-03,  ..., -5.4194e-01,\n",
       "            6.6705e-01, -3.2635e-01],\n",
       "          ...,\n",
       "          [ 5.6970e-01, -6.3729e-02,  9.9381e-01,  ..., -7.3891e-01,\n",
       "            7.7285e-01, -8.1469e-01],\n",
       "          [ 2.7167e-01, -2.1467e-01,  1.2711e+00,  ..., -6.5238e-01,\n",
       "            7.1518e-01, -9.3397e-01],\n",
       "          [ 7.1732e-01, -5.1517e-01,  1.1564e+00,  ..., -6.3275e-01,\n",
       "            6.6593e-01, -1.3828e+00]],\n",
       " \n",
       "         [[-1.7628e-01, -2.3573e-01,  2.6664e-01,  ..., -1.9666e-01,\n",
       "            1.2261e-01, -7.4980e-01],\n",
       "          [-1.7963e-01,  9.3370e-02,  7.8829e-01,  ..., -3.3027e-01,\n",
       "           -2.2543e-01, -7.4467e-01],\n",
       "          [ 2.2619e-01,  6.9856e-01, -2.3714e-01,  ..., -1.7713e-01,\n",
       "           -1.7007e-01, -1.0728e-01],\n",
       "          ...,\n",
       "          [ 7.8119e-01, -1.7122e-01,  9.7979e-01,  ..., -7.8270e-01,\n",
       "            7.1587e-01, -6.7391e-01],\n",
       "          [ 6.0594e-01, -3.3448e-01,  1.2602e+00,  ..., -6.8802e-01,\n",
       "            6.4969e-01, -9.1514e-01],\n",
       "          [ 9.1210e-01, -7.5146e-01,  1.1332e+00,  ..., -6.6984e-01,\n",
       "            5.8841e-01, -1.3461e+00]]], grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.2938,  0.1405,  0.7664,  ..., -0.4224,  0.2196, -0.9387],\n",
       "          [ 0.6494,  0.1477,  0.2730,  ..., -0.5098,  0.7316,  0.1096],\n",
       "          [ 0.0971,  0.7184,  0.1715,  ..., -1.0919,  0.4428, -0.7202],\n",
       "          ...,\n",
       "          [ 0.5948,  0.1599,  1.1538,  ..., -0.9811,  0.3403, -1.3241],\n",
       "          [ 0.2811,  0.0674,  1.4124,  ..., -0.9213,  0.2959, -1.3843],\n",
       "          [ 0.6801, -0.1555,  1.3051,  ..., -0.9570,  0.3556, -1.8380]],\n",
       " \n",
       "         [[-0.3627, -0.1350,  0.3595,  ..., -0.2522,  0.1503, -1.0787],\n",
       "          [-0.4809, -0.2402,  0.9855,  ..., -0.4494, -0.1238, -0.9969],\n",
       "          [ 0.2628,  0.8992,  0.0866,  ..., -0.3524,  0.0582, -0.3776],\n",
       "          ...,\n",
       "          [ 0.6974,  0.0381,  1.0829,  ..., -0.9017,  0.2748, -1.1681],\n",
       "          [ 0.5018, -0.0925,  1.3307,  ..., -0.8361,  0.2294, -1.3744],\n",
       "          [ 0.7664, -0.4655,  1.2052,  ..., -0.8497,  0.2547, -1.8151]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[ 0.1224,  0.3962,  0.8593,  ..., -0.6699,  0.3736, -0.8752],\n",
       "          [ 0.8881,  0.3258,  0.2836,  ..., -0.5143,  0.5550,  0.3936],\n",
       "          [ 0.1461,  1.0509,  0.3101,  ..., -0.8116,  0.5208, -0.1511],\n",
       "          ...,\n",
       "          [ 0.6638,  0.2881,  1.1853,  ..., -0.9298,  0.4183, -1.2481],\n",
       "          [ 0.3424,  0.1372,  1.3394,  ..., -0.8490,  0.3264, -1.2572],\n",
       "          [ 0.6926, -0.0882,  1.2818,  ..., -0.9140,  0.4103, -1.7239]],\n",
       " \n",
       "         [[ 0.0718,  0.2349,  0.5143,  ..., -0.5396,  0.0504, -1.0301],\n",
       "          [-0.3473, -0.0408,  0.7756,  ..., -0.4657, -0.1415, -0.5481],\n",
       "          [-0.0689,  0.9653,  0.2077,  ..., -0.4233,  0.0589,  0.4646],\n",
       "          ...,\n",
       "          [ 0.8455,  0.2106,  1.1713,  ..., -0.8582,  0.2544, -1.1708],\n",
       "          [ 0.6515,  0.0291,  1.3037,  ..., -0.7965,  0.2045, -1.3291],\n",
       "          [ 0.8598, -0.3290,  1.2249,  ..., -0.8589,  0.2646, -1.8129]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[-0.3638,  0.5134,  0.5495,  ..., -0.4841,  0.4963, -0.5592],\n",
       "          [ 0.2451, -0.1647,  0.3254,  ...,  0.0251,  0.6870,  0.3468],\n",
       "          [-0.1145,  0.4743,  0.3670,  ..., -0.1040,  0.4522,  0.1831],\n",
       "          ...,\n",
       "          [ 0.4062,  0.1322,  0.8410,  ..., -0.7967,  0.3255, -1.1899],\n",
       "          [ 0.2683,  0.0852,  0.9596,  ..., -0.7396,  0.2321, -1.0489],\n",
       "          [ 0.4787, -0.0018,  0.9689,  ..., -0.8042,  0.3525, -1.4292]],\n",
       " \n",
       "         [[-0.3720,  0.4194,  0.3879,  ..., -0.4801,  0.2841, -0.9154],\n",
       "          [-0.5130,  0.0353,  1.1188,  ..., -0.2336,  0.7592, -0.0448],\n",
       "          [-0.4853,  0.3472,  0.1404,  ..., -0.1242,  0.0666,  0.6161],\n",
       "          ...,\n",
       "          [ 0.5417,  0.1160,  0.8503,  ..., -0.8669,  0.0889, -1.2774],\n",
       "          [ 0.4392,  0.0624,  0.9680,  ..., -0.8067,  0.0308, -1.2666],\n",
       "          [ 0.6183, -0.0764,  0.9619,  ..., -0.8852,  0.1123, -1.6548]]],\n",
       "        grad_fn=<NativeLayerNormBackward>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
